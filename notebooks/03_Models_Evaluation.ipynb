{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15246538",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook summarizes and compares the results of all trained models, highlighting performance metrics, feature importance, and observations for model selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cddbee",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "599f0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c66b0b",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8b202",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "26e5800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the logistic_regression_baseline_results.csv path\n",
    "main_dir = os.path.dirname(os.getcwd())\n",
    "lr_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'lr_results.csv')\n",
    "dtc_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'dtc_results.csv')\n",
    "rfc_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'rfc_results.csv')\n",
    "xgbc_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'xgbc_results.csv')\n",
    "lr_log_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'lr_log_results.csv')\n",
    "dtc_log_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'dtc_log_results.csv')\n",
    "lr_standard_scaled_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'lr_standard_scaled_results.csv')\n",
    "dtc_standard_scaled_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'dtc_standard_scaled_results.csv')\n",
    "lr_min_max_scaled_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'lr_min_max_scaled_results.csv')\n",
    "dtc_min_max_scaled_file_path = os.path.join(main_dir, 'data', 'processed', 'Baseline', 'dtc_min_max_scaled_results.csv')\n",
    "\n",
    "# Load the model results.csv\n",
    "lr_results = pd.read_csv(lr_file_path)\n",
    "dtc_results = pd.read_csv(dtc_file_path)\n",
    "rfc_results = pd.read_csv(rfc_file_path)\n",
    "xgbc_results = pd.read_csv(xgbc_file_path)\n",
    "lr_log_results = pd.read_csv(lr_log_file_path)\n",
    "dtc_log_results = pd.read_csv(dtc_log_file_path)\n",
    "lr_standard_scaled_results = pd.read_csv(lr_standard_scaled_file_path)\n",
    "dtc_standard_scaled_results = pd.read_csv(dtc_standard_scaled_file_path)\n",
    "lr_min_max_scaled_results = pd.read_csv(lr_min_max_scaled_file_path)\n",
    "dtc_min_max_scaled_results = pd.read_csv(dtc_min_max_scaled_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b26b6",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fda8526a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features_used</th>\n",
       "      <th>params_used</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>[[89, 21], [13, 56]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>[[98, 12], [21, 48]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>[[94, 16], [20, 49]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>[[94, 16], [17, 52]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Log</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>[[89, 21], [13, 56]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier Log</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>[[98, 12], [21, 48]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression Standard Scaled</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>[[89, 21], [13, 56]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree Classifier Standard Scaled</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>[[98, 12], [21, 48]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression MinMax Scaled</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>[[90, 20], [13, 56]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree Classifier MinMax Scaled</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>[[98, 12], [21, 48]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model  \\\n",
       "0                       Logistic Regression   \n",
       "1                  Decision Tree Classifier   \n",
       "2                  Random Forest Classifier   \n",
       "3                        XGBoost Classifier   \n",
       "4                   Logistic Regression Log   \n",
       "5              Decision Tree Classifier Log   \n",
       "6       Logistic Regression Standard Scaled   \n",
       "7  Decision Tree Classifier Standard Scaled   \n",
       "8         Logistic Regression MinMax Scaled   \n",
       "9    Decision Tree Classifier MinMax Scaled   \n",
       "\n",
       "                             features_used params_used  accuracy_score  \\\n",
       "0  features selected manually based on EDA     default        0.810056   \n",
       "1  features selected manually based on EDA     default        0.815642   \n",
       "2  features selected manually based on EDA     default        0.798883   \n",
       "3  features selected manually based on EDA     default        0.815642   \n",
       "4  features selected manually based on EDA     default        0.810056   \n",
       "5  features selected manually based on EDA     default        0.815642   \n",
       "6  features selected manually based on EDA     default        0.810056   \n",
       "7  features selected manually based on EDA     default        0.815642   \n",
       "8  features selected manually based on EDA     default        0.815642   \n",
       "9  features selected manually based on EDA     default        0.815642   \n",
       "\n",
       "   f1_score  precision_score  recall_score      confusion_matrix notes  \n",
       "0  0.767123         0.727273      0.811594  [[89, 21], [13, 56]]  None  \n",
       "1  0.744186         0.800000      0.695652  [[98, 12], [21, 48]]  None  \n",
       "2  0.731343         0.753846      0.710145  [[94, 16], [20, 49]]  None  \n",
       "3  0.759124         0.764706      0.753623  [[94, 16], [17, 52]]  None  \n",
       "4  0.767123         0.727273      0.811594  [[89, 21], [13, 56]]  None  \n",
       "5  0.744186         0.800000      0.695652  [[98, 12], [21, 48]]  None  \n",
       "6  0.767123         0.727273      0.811594  [[89, 21], [13, 56]]  None  \n",
       "7  0.744186         0.800000      0.695652  [[98, 12], [21, 48]]  None  \n",
       "8  0.772414         0.736842      0.811594  [[90, 20], [13, 56]]  None  \n",
       "9  0.744186         0.800000      0.695652  [[98, 12], [21, 48]]  None  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a function to compute all the evaluation metrics and store them inside a DataFrame\n",
    "def model_evaluation(df, model_name='Model', features_used = 'features selected manually based on EDA', params = None, notes = None, y_val='y_val', y_pred='y_pred'):\n",
    "    metrics = {\n",
    "        'model': [model_name],\n",
    "        'features_used': [features_used if features_used else \"default\"],\n",
    "        'params_used': [params if params else 'default'],\n",
    "        'accuracy_score': [accuracy_score(df[y_val], df[y_pred])],\n",
    "        'f1_score': [f1_score(df[y_val], df[y_pred])],\n",
    "        'precision_score': [precision_score(df[y_val], df[y_pred])],\n",
    "        'recall_score': [recall_score(df[y_val], df[y_pred])],\n",
    "        'confusion_matrix': [confusion_matrix(df[y_val], df[y_pred])],\n",
    "        'notes': [notes if notes else None]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Call the function\n",
    "df_lr_eval = model_evaluation(lr_results, 'Logistic Regression')\n",
    "df_dtc_eval = model_evaluation(dtc_results, 'Decision Tree Classifier')\n",
    "df_rfc_eval = model_evaluation(rfc_results, 'Random Forest Classifier')\n",
    "df_xgbc_eval = model_evaluation(xgbc_results, 'XGBoost Classifier')\n",
    "df_lr_log_eval = model_evaluation(lr_log_results, 'Logistic Regression Log')\n",
    "df_dtc_log_eval = model_evaluation(dtc_log_results, 'Decision Tree Classifier Log')\n",
    "df_lr_standard_scaled_eval = model_evaluation(lr_standard_scaled_results, 'Logistic Regression Standard Scaled')\n",
    "df_dtc_standard_scaled_eval = model_evaluation(dtc_standard_scaled_results, 'Decision Tree Classifier Standard Scaled')\n",
    "df_lr_min_max_scaled_eval = model_evaluation(lr_min_max_scaled_results, 'Logistic Regression MinMax Scaled')\n",
    "df_dtc_min_max_scaled_eval = model_evaluation(dtc_min_max_scaled_results, 'Decision Tree Classifier MinMax Scaled')\n",
    "\n",
    "# Concatenate all eval into a single DataFrame\n",
    "df_metrics = pd.concat([\n",
    "    df_lr_eval, \n",
    "    df_dtc_eval,\n",
    "    df_rfc_eval,\n",
    "    df_xgbc_eval,\n",
    "    df_lr_log_eval,\n",
    "    df_dtc_log_eval,\n",
    "    df_lr_standard_scaled_eval,\n",
    "    df_dtc_standard_scaled_eval,\n",
    "    df_lr_min_max_scaled_eval,\n",
    "    df_dtc_min_max_scaled_eval]).reset_index(drop = True)\n",
    "df_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb06184",
   "metadata": {},
   "source": [
    "## Comparisons and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98423dd",
   "metadata": {},
   "source": [
    "Model 0 – Logistic Regression\n",
    "The model was trained using the base features: Pclass, Fare, Sex, and Embarked.\n",
    "It achieves an accuracy of ~81%, which is acceptable as a baseline. However, since the goal is to predict passenger survival, we place greater emphasis on the Precision Score (TP / (TP + FP)), which currently stands at ~72.7%.\n",
    "\n",
    "A higher precision indicates that when the model predicts a passenger will survive, there is a higher probability that this prediction is correct. This reduces the number of false positives (21 cases), where the model predicts survival but the passenger did not survive.\n",
    "\n",
    "Model 1 – Decision Tree Classifier\n",
    "The model was trained using the same features as Model 0. We observe a significant improvement in Precision, which increased from ~72.7% to 80%. The Recall decreased from 81% to 69%, but since precision is our priority, the Decision Tree Classifier is considered superior in this context. The accuracy also shows a slight improvement.\n",
    "\n",
    "Conclusion:\n",
    "Based on our metrics and the prioritization of precision, the Decision Tree Classifier provides better predictive reliability for identifying survivors, making it the preferred baseline model for further experiments and feature engineering.\n",
    "\n",
    "Model 2 - Random Forest Classifier\n",
    "This is an ensemble model and usually the scores should exceed baseline models but since we didn't use Pipeline and we kept the model quite standard without feature engineering and parameters tuning, the scores are similar or even a little bit worse compared to Model 1.\n",
    "\n",
    "Model 3 - XGBoost Classifier\n",
    "The same as Model 2\n",
    "\n",
    "Next steps would be to begin the feature engineering phase to see how the models evolve.\n",
    "\n",
    "After log-transforming and Scaling the \"Fare\" column, models 4-9 don't seem to improve too much, therefore we will stick with Model 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9fef9",
   "metadata": {},
   "source": [
    "# Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fc237",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9f616b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = os.path.dirname(os.getcwd())\n",
    "rfc_path = os.path.join(main_dir, 'data', 'processed', 'Advanced', 'rfc_results.csv')\n",
    "rfc_hyperparam_path = os.path.join(main_dir, 'data', 'processed', 'Advanced', 'rfc_hyperparam_results.csv')\n",
    "rfc_hyperparam_auto_path = os.path.join(main_dir, 'data', 'processed', 'Advanced', 'rfc_hyperparam_auto_results.csv')\n",
    "rfc_auto_selected_path = os.path.join(main_dir, 'data', 'processed', 'Advanced', 'df_rfc_auto_selected_results.csv')\n",
    "\n",
    "rfc_results = pd.read_csv(rfc_path)\n",
    "rfc_hyperparam_results = pd.read_csv(rfc_hyperparam_path)\n",
    "rfc_hyperparam_auto_results = pd.read_csv(rfc_hyperparam_auto_path)\n",
    "rfc_auto_selected_results = pd.read_csv(rfc_auto_selected_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41fc8a",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93efb3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features_used</th>\n",
       "      <th>params_used</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>default</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>[[84, 19], [21, 55]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ranom Forest Classifier</td>\n",
       "      <td>features selected manually based on EDA</td>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.732026</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>[[82, 21], [20, 56]]</td>\n",
       "      <td>Parameters were selected base on RandomizedSea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ranom Forest Classifier</td>\n",
       "      <td>All features</td>\n",
       "      <td>default</td>\n",
       "      <td>0.781206</td>\n",
       "      <td>0.706767</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>[[369, 70], [86, 188]]</td>\n",
       "      <td>Include all features and let the model to sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ranom Forest Classifier</td>\n",
       "      <td>Auto selected features</td>\n",
       "      <td>default</td>\n",
       "      <td>0.796634</td>\n",
       "      <td>0.724858</td>\n",
       "      <td>0.754941</td>\n",
       "      <td>0.697080</td>\n",
       "      <td>[[377, 62], [83, 191]]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model                            features_used  \\\n",
       "0  Random Forest Classifier  features selected manually based on EDA   \n",
       "1   Ranom Forest Classifier  features selected manually based on EDA   \n",
       "2   Ranom Forest Classifier                             All features   \n",
       "3   Ranom Forest Classifier                   Auto selected features   \n",
       "\n",
       "          params_used  accuracy_score  f1_score  precision_score  \\\n",
       "0             default        0.776536  0.733333         0.743243   \n",
       "1  RandomizedSearchCV        0.770950  0.732026         0.727273   \n",
       "2             default        0.781206  0.706767         0.728682   \n",
       "3             default        0.796634  0.724858         0.754941   \n",
       "\n",
       "   recall_score        confusion_matrix  \\\n",
       "0      0.723684    [[84, 19], [21, 55]]   \n",
       "1      0.736842    [[82, 21], [20, 56]]   \n",
       "2      0.686131  [[369, 70], [86, 188]]   \n",
       "3      0.697080  [[377, 62], [83, 191]]   \n",
       "\n",
       "                                               notes  \n",
       "0                                               None  \n",
       "1  Parameters were selected base on RandomizedSea...  \n",
       "2  Include all features and let the model to sele...  \n",
       "3                                               None  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "df_rfc_eval = model_evaluation(rfc_results, \"Random Forest Classifier\")\n",
    "df_rfc_hyperparam_eval = model_evaluation(rfc_hyperparam_results, \"Ranom Forest Classifier\", params = 'RandomizedSearchCV', notes = 'Parameters were selected base on RandomizedSearchCV')\n",
    "df_rfc_hyperparam_auto_eval =  model_evaluation(rfc_hyperparam_auto_results, \"Ranom Forest Classifier\", features_used = 'All features', notes = 'Include all features and let the model to select them. Review Feature Importance from 02_ML_Models')\n",
    "df_rfc_auto_selected_eval =  model_evaluation(rfc_auto_selected_results, \"Ranom Forest Classifier\", features_used = 'Auto selected features')\n",
    "\n",
    "\n",
    "# Combine the results in a DataFrame\n",
    "df_advanced_metrics = pd.concat([\n",
    "    df_rfc_eval,\n",
    "    df_rfc_hyperparam_eval,\n",
    "    df_rfc_hyperparam_auto_eval,\n",
    "    df_rfc_auto_selected_eval\n",
    "]).reset_index(drop = True)\n",
    "\n",
    "df_advanced_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c4334",
   "metadata": {},
   "source": [
    "## Comparisons and Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9c03a",
   "metadata": {},
   "source": [
    "Model 0 – Random Forest Classifier\n",
    "Although Random Forest is an ensemble model that typically outperforms baseline algorithms, in this case it was trained with a simple pipeline, default hyperparameters, and without advanced feature engineering. As a result, the evaluation metrics did not improve significantly compared to the baseline models.\n",
    "\n",
    "In fact, the Decision Tree Classifier (baseline) still provides the best precision score, which aligns with our initial objective of minimizing false positives.\n",
    "\n",
    "Model 1 – Random Forest Classifier with hyperparameter tuning\n",
    "Hyperparameters were optimized using RandomizedSearchCV, but tuning alone was not sufficient to improve the precision score meaningfully. This confirms that, given the simplicity of the current features, the model cannot extract significantly more predictive power without additional informative features.\n",
    "\n",
    "Next Steps\n",
    "The logical next step is feature engineering: creating additional features derived from the existing columns (e.g., Title from Name, FamilySize, IsAlone, binned Age, interaction terms, etc.) in the 01_EDA notebook. After generating these new features, the pipeline and hyperparameter tuning can be re-applied to evaluate the true potential of Random Forest and other ensemble models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5e698",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
